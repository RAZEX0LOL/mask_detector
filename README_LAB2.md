# Лабораторная работа 2: Сбор данных и статистика

## Описание

Данный репозиторий содержит материалы для Лабораторной работы 2 по сбору данных и статистическому анализу для системы обнаружения масок на лице.

## Структура проекта

```
mask_detector/
├── lab2_data_collection_and_statistics.ipynb  # Основной Jupyter Notebook
├── SOURCES.md                                  # Список авторитетных источников
├── README_LAB2.md                             # Данная инструкция
├── detect_mask_video.py                       # Приложение для детекции масок
├── mask_detector.keras                        # Обученная модель
├── face_detector/                             # Модель детекции лиц
│   ├── deploy.prototxt
│   └── res10_300x300_ssd_iter_140000.caffemodel
└── requirements.txt                           # Зависимости
```

## Требования к окружению

### Установка зависимостей

```bash
pip install jupyter numpy pandas matplotlib seaborn opencv-python scikit-learn scipy
```

Или из файла requirements.txt:
```bash
pip install -r requirements.txt
pip install jupyter pandas seaborn scipy
```

### Минимальные требования

- Python 3.7+
- Jupyter Notebook / JupyterLab
- NumPy >= 1.18.0
- Pandas >= 1.0.0
- Matplotlib >= 3.1.0
- Seaborn >= 0.10.0
- OpenCV >= 4.2.0
- Scikit-learn >= 0.22.0
- SciPy >= 1.4.0

## Как использовать

### 1. Запуск Jupyter Notebook

```bash
cd ~/mask_detector
jupyter notebook lab2_data_collection_and_statistics.ipynb
```

### 2. Подготовка данных

#### Вариант А: Использование реального датасета

1. Скачайте датасет с Kaggle:
   - Face Mask Detection Dataset: https://www.kaggle.com/datasets/omkargurav/face-mask-dataset

2. Разместите данные в структуре:
   ```
   dataset/
   ├── with_mask/
   └── without_mask/
   ```

3. Обновите путь в ячейке с `DATASET_PATH` в notebook:
   ```python
   DATASET_PATH = Path("dataset")  # Укажите ваш путь
   ```

#### Вариант Б: Использование симулированных данных

Notebook автоматически создаст симулированные данные для демонстрации, если реальный датасет не найден. Это позволяет:
- Ознакомиться со структурой анализа
- Протестировать все визуализации
- Понять методологию работы с данными

### 3. Выполнение анализа

Последовательно выполните все ячейки notebook (Cell → Run All):

1. **Импорт библиотек** - загрузка необходимых модулей
2. **Описание датасета** - информация об источниках данных
3. **Загрузка данных** - чтение и структурирование данных
4. **Статистический анализ** - вычисление метрик и тестов
5. **Визуализация** - создание графиков и диаграмм
6. **Подготовка данных** - разделение на train/validation
7. **Выводы** - объективные заключения на основе анализа

## Содержание работы

### Основные разделы

1. **Введение**
   - Постановка задачи
   - Цели работы
   - Методология

2. **Описание датасета**
   - Источники данных
   - Структура данных
   - Авторитетность источников

3. **Сбор и подготовка данных**
   - Процесс сбора
   - Контроль качества
   - Предварительная обработка

4. **Статистический анализ**
   - Анализ распределения классов
   - Анализ размеров изображений
   - Статистические тесты (t-test)
   - Корреляционный анализ

5. **Визуализация данных**
   - Графики распределения классов
   - Гистограммы размеров изображений
   - Box plots для сравнения классов
   - Корреляционные матрицы

6. **Подготовка данных для обучения**
   - Стратифицированное разделение (80/20)
   - Рекомендации по аугментации
   - Сохранение разделения

7. **Выводы**
   - Объективные заключения
   - Рекомендации
   - Научная обоснованность

8. **Список источников**
   - 15+ авторитетных источников
   - Монографии и журналы
   - Детальная библиография в SOURCES.md

## Критерии оценивания

### Структурированность результата (5 баллов)
- ✅ Четкая структура документа
- ✅ Логическое изложение материала
- ✅ Оглавление и навигация
- ✅ Понятные заголовки и описания

### Визуализация данных (5 баллов)
- ✅ Графики распределения классов (bar chart, pie chart)
- ✅ Гистограммы размеров изображений
- ✅ Box plots для сравнения характеристик
- ✅ Корреляционная матрица (heatmap)
- ✅ Профессиональное оформление графиков

### Авторитетность источников (5 баллов)
- ✅ Монографии: Goodfellow et al., Bishop, Hastie et al.
- ✅ Журналы Q1: Measurement, Smart Health
- ✅ Конференции: NIPS
- ✅ Более 15 источников в SOURCES.md
- ✅ Корректное цитирование

### Качество работы - объективность выводов (10 баллов)
- ✅ Статистический анализ (описательная статистика, t-test)
- ✅ Проверка баланса классов
- ✅ Анализ технических характеристик изображений
- ✅ Объективные выводы на основе данных
- ✅ Рекомендации, основанные на анализе
- ✅ Научная обоснованность заключений

**Итого: 25 баллов**

## Выходные файлы

После выполнения notebook будут созданы:

1. **train_dataset.csv** - информация об обучающей выборке
2. **val_dataset.csv** - информация о валидационной выборке

Эти файлы можно использовать для последующего обучения модели.

## Дополнительные материалы

### SOURCES.md

Файл содержит детальную библиографию со следующей информацией для каждого источника:
- Полное название
- Авторы
- Год публикации
- Издательство/журнал
- ISBN/DOI
- Описание
- Ссылки

### Рекомендации по улучшению

1. **Расширение датасета**
   - Добавить больше данных для повышения разнообразия
   - Использовать дополнительные источники (RMFD, MaskedFace-Net)

2. **Дополнительный анализ**
   - Анализ качества изображений (blur detection)
   - Анализ освещенности
   - Детекция выбросов (outliers)

3. **Аугментация данных**
   - Реализовать pipeline аугментации
   - Визуализировать примеры аугментированных изображений

## Публикация на GitHub

### Подготовка к публикации

1. Убедитесь, что все ячейки выполнены и содержат результаты
2. Очистите вывод ячеек при необходимости (Cell → All Output → Clear)
3. Сохраните notebook

### Создание репозитория

```bash
cd ~/mask_detector
git init
git add lab2_data_collection_and_statistics.ipynb
git add SOURCES.md
git add README_LAB2.md
git commit -m "Add Lab 2: Data Collection and Statistics"
git branch -M main
git remote add origin https://github.com/YOUR_USERNAME/mask-detector.git
git push -u origin main
```

### Файлы для коммита

Рекомендуется включить в репозиторий:
- ✅ lab2_data_collection_and_statistics.ipynb
- ✅ SOURCES.md
- ✅ README_LAB2.md
- ✅ requirements.txt
- ⚠️ НЕ включать: датасеты (слишком большие), модели (.keras файлы)

Добавьте `.gitignore`:
```
dataset/
*.keras
*.caffemodel
*.csv
__pycache__/
.ipynb_checkpoints/
```

## Часто задаваемые вопросы

### Q: Что делать, если нет датасета?

**A:** Notebook автоматически создаст симулированные данные для демонстрации. Для реального проекта скачайте датасет с Kaggle.

### Q: Как интерпретировать результаты статистического теста?

**A:** p-value < 0.05 указывает на статистически значимое различие между группами. В нашем случае анализируется, различаются ли технические характеристики изображений между классами.

### Q: Почему используется стратифицированное разделение?

**A:** Стратификация сохраняет пропорции классов в обучающей и валидационной выборках, что важно для корректного обучения модели.

### Q: Как добавить свои источники?

**A:** Отредактируйте файл SOURCES.md и добавьте ссылки на источники в соответствующий раздел notebook (раздел 8).

## Контакты и поддержка

При возникновении вопросов:
1. Проверьте документацию использованных библиотек
2. Обратитесь к SOURCES.md для детальной информации об источниках
3. Изучите комментарии в коде notebook

